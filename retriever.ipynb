{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWpbp0N9fkPX",
        "outputId": "c3988084-c798-46a0-884d-de553fa3b86f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/CS231n-Final-Project/small-dataset\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "DIRECTORY = \"/content/drive/My Drive/CS231n-Final-Project/small-dataset\"\n",
        "%cd $DIRECTORY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFy0pdwMfZ-9",
        "outputId": "7c729fd6-918e-4dcb-c991-215be1a6f6cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.utils.data import sampler\n",
        "\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "USE_GPU = True\n",
        "dtype = torch.float32 # We will be using float throughout this tutorial.\n",
        "\n",
        "if USE_GPU and torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "# Constant to control how frequently we print train loss.\n",
        "print_every = 100\n",
        "print('using device:', device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wVssOaGbDPUI"
      },
      "outputs": [],
      "source": [
        "imageEmbeddingSize, queryTextEmbeddingSize = 512, 384"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BWelGQatLZ7y"
      },
      "outputs": [],
      "source": [
        "from ast import literal_eval\n",
        "\n",
        "# Load in data and unwrap it\n",
        "# Function to convert stringified tuple keys back to tuples\n",
        "def unwrap_keys(mapping):\n",
        "    return {literal_eval(k): v for k, v in mapping.items()}\n",
        "\n",
        "# Load the JSON file\n",
        "with open('./clip_embeddings.json', 'r') as json_file:\n",
        "    data_from_json = json.load(json_file)\n",
        "\n",
        "# print(data_from_json)\n",
        "# Unwrap the keys to their original tuple format\n",
        "unwrapped_data = unwrap_keys(data_from_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_A5Lsxeq6-w",
        "outputId": "67e66436-e2d4-4ce9-dff1-188e6e87b4f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "224 224 224\n"
          ]
        }
      ],
      "source": [
        "text_key = \"text_embedding\"\n",
        "image_key = \"image_embeddings_all\"\n",
        "score_key = \"scores\"\n",
        "image_embeddings_top_5 = \"image_embeddings_top5_idx\"\n",
        "image_embeddings = []\n",
        "text_embeddings = []\n",
        "y_output = []\n",
        "X_image_eval = []\n",
        "X_text_embed_eval = []\n",
        "y_eval = []\n",
        "prompts = []\n",
        "for key, sub_dataset in unwrapped_data.items():\n",
        "  # pprint.pp(sub_dataset)\n",
        "  text_embedding = sub_dataset[text_key]\n",
        "  image_embedding = sub_dataset[image_key]\n",
        "  # print(len(image_embedding))\n",
        "  scores = sub_dataset[score_key]\n",
        "  top5 = sub_dataset[image_embeddings_top_5]\n",
        "  # print(len(image_embedding), len(text_embedding), len(scores))\n",
        "  # if len(image_embedding) != len(scores):\n",
        "  #   continue\n",
        "  # print(top5, len(image_embedding))\n",
        "  # print(key)\n",
        "  for i in range(1):\n",
        "    idx = top5[i]\n",
        "    # print(top5, len(image_embedding))\n",
        "    if idx >= len(image_embedding):\n",
        "      # print(top5, len(image_embedding))\n",
        "      print(key)\n",
        "      continue\n",
        "    image_embeddings.append(image_embedding[idx])\n",
        "    text_embeddings.append(text_embedding)\n",
        "    y_output.append(scores[i])\n",
        "  if top5[0] == 0:\n",
        "    continue\n",
        "  X_image_eval.append(image_embedding)\n",
        "  X_text_embed_eval.append([text_embedding] * len(image_embedding))\n",
        "  y_eval.append(top5)\n",
        "  prompts.append(key)\n",
        "\n",
        "# print(y_output)\n",
        "N = len(image_embeddings)\n",
        "print(len(image_embeddings), len(text_embeddings), len(y_output))\n",
        "# print(y_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJI9LC23qRFj",
        "outputId": "ba1cf3e6-7902-4c3a-abca-72773539ebdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([224, 512]) torch.Size([224, 384]) torch.Size([224])\n"
          ]
        }
      ],
      "source": [
        "X_images = torch.tensor(image_embeddings).squeeze()\n",
        "X_queries = torch.tensor(text_embeddings)\n",
        "y = torch.tensor(y_output)\n",
        "print(X_images.shape, X_queries.shape, y.shape)\n",
        "dataset = TensorDataset(X_images, X_queries, y)\n",
        "batch_size = 32\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "# print(X_images.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kvJJm9zsf2BO"
      },
      "outputs": [],
      "source": [
        "class EmbeddingProjectionNN(nn.Module):\n",
        "    def __init__(self, embeddingSize):\n",
        "      super().__init__()\n",
        "      self.linear_relu_stack = nn.Sequential(\n",
        "          nn.Linear(embeddingSize, 512),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(),\n",
        "          nn.Linear(512, 512),\n",
        "          nn.LayerNorm(512),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(),\n",
        "          nn.Linear(512, 256),\n",
        "          nn.Tanh()\n",
        "      )\n",
        "\n",
        "    def forward(self, x):\n",
        "      # input (N, E)\n",
        "      projection = self.linear_relu_stack(x)\n",
        "      return projection\n",
        "\n",
        "class RetrieverNN(nn.Module):\n",
        "  def __init__(self, imageEmbedding, queryEmbedding):\n",
        "    super().__init__()\n",
        "    self.imageProj = EmbeddingProjectionNN(imageEmbedding)\n",
        "    self.queryProj = EmbeddingProjectionNN(queryEmbedding)\n",
        "    self.similarity = nn.CosineSimilarity(dim=1)\n",
        "\n",
        "\n",
        "  def forward(self, images, query):\n",
        "    imageProj = self.imageProj(images)\n",
        "    queryProj = self.queryProj(query)\n",
        "    similarities = self.similarity(imageProj, queryProj)\n",
        "    # make similarities a prob scores between 0 and 1\n",
        "    scores = similarities * 0.5 + 0.5\n",
        "    return scores\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3thaF3qkk8aW"
      },
      "outputs": [],
      "source": [
        "loss = nn.BCELoss()\n",
        "def train_part34(model, optimizer, epochs=10, scheduler = None):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "    - model: A PyTorch Module giving the model to train.\n",
        "    - optimizer: An Optimizer object we will use to train the model\n",
        "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
        "\n",
        "    Returns: Nothing, but prints model accuracies during training.\n",
        "    \"\"\"\n",
        "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
        "    for e in range(epochs):\n",
        "        for imageEmbeddings, queryEmbedding, y in dataloader:\n",
        "          # (B, E1), (B, E2), (B,)\n",
        "          model.train()  # put model to training mode\n",
        "          imageEmbeddings = imageEmbeddings.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
        "          queryEmbedding = queryEmbedding.to(device=device, dtype=dtype)\n",
        "          y = y.to(device=device, dtype=dtype)\n",
        "\n",
        "          scores = model(imageEmbeddings, queryEmbedding)\n",
        "          # print(scores)\n",
        "          # print(y)\n",
        "          output = loss(scores, y)\n",
        "          # print(scores, y)\n",
        "\n",
        "          # Zero out all of the gradients for the variables which the optimizer\n",
        "          # will update.\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # This is the backwards pass: compute the gradient of the loss with\n",
        "          # respect to each  parameter of the model.\n",
        "          output.backward()\n",
        "\n",
        "          # Actually update the parameters of the model using the gradients\n",
        "          # computed by the backwards pass.\n",
        "          optimizer.step()\n",
        "          if scheduler:\n",
        "            scheduler.step()\n",
        "          print('Iteration %d, loss = %.4f' % (e, output.item()))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVxih4THo1JC",
        "outputId": "bb2996d5-672a-4432-9d91-9e014006dd2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 0, loss = 0.6921\n",
            "Iteration 0, loss = 0.6902\n",
            "Iteration 0, loss = 0.8683\n",
            "Iteration 0, loss = 0.7305\n",
            "Iteration 0, loss = 0.6703\n",
            "Iteration 0, loss = 0.6261\n",
            "Iteration 0, loss = 0.5144\n",
            "Iteration 1, loss = 0.5991\n",
            "Iteration 1, loss = 0.5107\n",
            "Iteration 1, loss = 0.5712\n",
            "Iteration 1, loss = 0.4067\n",
            "Iteration 1, loss = 0.6026\n",
            "Iteration 1, loss = 0.5231\n",
            "Iteration 1, loss = 0.5346\n",
            "Iteration 2, loss = 0.4555\n",
            "Iteration 2, loss = 0.5263\n",
            "Iteration 2, loss = 0.4441\n",
            "Iteration 2, loss = 0.5994\n",
            "Iteration 2, loss = 0.4538\n",
            "Iteration 2, loss = 0.5415\n",
            "Iteration 2, loss = 0.4855\n",
            "Iteration 3, loss = 0.4552\n",
            "Iteration 3, loss = 0.5680\n",
            "Iteration 3, loss = 0.4143\n",
            "Iteration 3, loss = 0.4618\n",
            "Iteration 3, loss = 0.4579\n",
            "Iteration 3, loss = 0.4654\n",
            "Iteration 3, loss = 0.3881\n",
            "Iteration 4, loss = 0.3814\n",
            "Iteration 4, loss = 0.3554\n",
            "Iteration 4, loss = 0.4721\n",
            "Iteration 4, loss = 0.5502\n",
            "Iteration 4, loss = 0.3796\n",
            "Iteration 4, loss = 0.4187\n",
            "Iteration 4, loss = 0.5285\n",
            "Iteration 5, loss = 0.3585\n",
            "Iteration 5, loss = 0.3889\n",
            "Iteration 5, loss = 0.3772\n",
            "Iteration 5, loss = 0.3285\n",
            "Iteration 5, loss = 0.4248\n",
            "Iteration 5, loss = 0.4292\n",
            "Iteration 5, loss = 0.4448\n",
            "Iteration 6, loss = 0.4056\n",
            "Iteration 6, loss = 0.3718\n",
            "Iteration 6, loss = 0.2890\n",
            "Iteration 6, loss = 0.2967\n",
            "Iteration 6, loss = 0.4926\n",
            "Iteration 6, loss = 0.3052\n",
            "Iteration 6, loss = 0.3214\n",
            "Iteration 7, loss = 0.2357\n",
            "Iteration 7, loss = 0.3981\n",
            "Iteration 7, loss = 0.4442\n",
            "Iteration 7, loss = 0.3596\n",
            "Iteration 7, loss = 0.2080\n",
            "Iteration 7, loss = 0.2779\n",
            "Iteration 7, loss = 0.3381\n",
            "Iteration 8, loss = 0.5067\n",
            "Iteration 8, loss = 0.2939\n",
            "Iteration 8, loss = 0.3069\n",
            "Iteration 8, loss = 0.2387\n",
            "Iteration 8, loss = 0.2957\n",
            "Iteration 8, loss = 0.3436\n",
            "Iteration 8, loss = 0.3410\n",
            "Iteration 9, loss = 0.3741\n",
            "Iteration 9, loss = 0.1002\n",
            "Iteration 9, loss = 0.2459\n",
            "Iteration 9, loss = 0.4226\n",
            "Iteration 9, loss = 0.3549\n",
            "Iteration 9, loss = 0.3457\n",
            "Iteration 9, loss = 0.3034\n",
            "Iteration 10, loss = 0.2277\n",
            "Iteration 10, loss = 0.2762\n",
            "Iteration 10, loss = 0.2168\n",
            "Iteration 10, loss = 0.4933\n",
            "Iteration 10, loss = 0.1945\n",
            "Iteration 10, loss = 0.3492\n",
            "Iteration 10, loss = 0.2661\n",
            "Iteration 11, loss = 0.1074\n",
            "Iteration 11, loss = 0.2882\n",
            "Iteration 11, loss = 0.2464\n",
            "Iteration 11, loss = 0.3442\n",
            "Iteration 11, loss = 0.3359\n",
            "Iteration 11, loss = 0.2654\n",
            "Iteration 11, loss = 0.3192\n",
            "Iteration 12, loss = 0.3104\n",
            "Iteration 12, loss = 0.3127\n",
            "Iteration 12, loss = 0.3477\n",
            "Iteration 12, loss = 0.3246\n",
            "Iteration 12, loss = 0.3436\n",
            "Iteration 12, loss = 0.2940\n",
            "Iteration 12, loss = 0.1644\n",
            "Iteration 13, loss = 0.3121\n",
            "Iteration 13, loss = 0.5509\n",
            "Iteration 13, loss = 0.1845\n",
            "Iteration 13, loss = 0.4335\n",
            "Iteration 13, loss = 0.2756\n",
            "Iteration 13, loss = 0.2099\n",
            "Iteration 13, loss = 0.3452\n",
            "Iteration 14, loss = 0.3835\n",
            "Iteration 14, loss = 0.3555\n",
            "Iteration 14, loss = 0.3665\n",
            "Iteration 14, loss = 0.1956\n",
            "Iteration 14, loss = 0.2263\n",
            "Iteration 14, loss = 0.2656\n",
            "Iteration 14, loss = 0.3591\n",
            "Iteration 15, loss = 0.3013\n",
            "Iteration 15, loss = 0.3145\n",
            "Iteration 15, loss = 0.2555\n",
            "Iteration 15, loss = 0.2336\n",
            "Iteration 15, loss = 0.1934\n",
            "Iteration 15, loss = 0.4213\n",
            "Iteration 15, loss = 0.1563\n",
            "Iteration 16, loss = 0.2146\n",
            "Iteration 16, loss = 0.2011\n",
            "Iteration 16, loss = 0.2959\n",
            "Iteration 16, loss = 0.3362\n",
            "Iteration 16, loss = 0.1985\n",
            "Iteration 16, loss = 0.2086\n",
            "Iteration 16, loss = 0.4088\n",
            "Iteration 17, loss = 0.2138\n",
            "Iteration 17, loss = 0.3540\n",
            "Iteration 17, loss = 0.3227\n",
            "Iteration 17, loss = 0.1766\n",
            "Iteration 17, loss = 0.3367\n",
            "Iteration 17, loss = 0.3163\n",
            "Iteration 17, loss = 0.2406\n",
            "Iteration 18, loss = 0.5021\n",
            "Iteration 18, loss = 0.1112\n",
            "Iteration 18, loss = 0.2633\n",
            "Iteration 18, loss = 0.2361\n",
            "Iteration 18, loss = 0.3110\n",
            "Iteration 18, loss = 0.3585\n",
            "Iteration 18, loss = 0.3231\n",
            "Iteration 19, loss = 0.4465\n",
            "Iteration 19, loss = 0.2962\n",
            "Iteration 19, loss = 0.2587\n",
            "Iteration 19, loss = 0.3119\n",
            "Iteration 19, loss = 0.1743\n",
            "Iteration 19, loss = 0.1828\n",
            "Iteration 19, loss = 0.1347\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = RetrieverNN(imageEmbeddingSize, queryTextEmbeddingSize)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "train_part34(model, optimizer, epochs = 20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuDiH8VwN-_y",
        "outputId": "3f4249f0-a602-450c-93cb-17b567c5939e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n",
            "0.115 0.395\n"
          ]
        }
      ],
      "source": [
        "# Check if a GPU is available and if not, use the CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "# Move the model to the appropriate device\n",
        "model.to(device)\n",
        "model.eval()  # set model to evaluation mode\n",
        "eval_loose = 0\n",
        "eval_tight = 0\n",
        "N = len(X_image_eval)\n",
        "with torch.no_grad():\n",
        "  for i in range(N):\n",
        "    X_image = torch.tensor(X_image_eval[i]).squeeze().to(device)\n",
        "    # print(X_image.shape)\n",
        "    X_query_eval = torch.tensor(X_text_embed_eval[i]).to(device)\n",
        "    # print(X_query_eval.shape)\n",
        "    top5 = y_eval[i]\n",
        "    probs = model(X_image, X_query_eval).cpu()\n",
        "    top_pred = probs.detach().numpy().squeeze()\n",
        "    # print(prompts[i])\n",
        "    # print(top_pred.shape)\n",
        "    pred_idx = np.argmax(top_pred)\n",
        "    if pred_idx in top5:\n",
        "      eval_loose += 1\n",
        "    if pred_idx == top5[0]:\n",
        "      eval_tight += 1\n",
        "print(float(eval_tight)/ N, float(eval_loose)/N)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQnIByP_tObl"
      },
      "source": [
        "## Connect to Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OjVluq35NEE",
        "outputId": "ff213060-f399-4083-9612-ef831237594f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(20,)\n",
            "[1 2 3 9 6]\n",
            "[1, 1, 1, 1, 1]\n",
            "Successfully retrieved image embeddings\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from ast import literal_eval\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "# from huggingface_hub import login\n",
        "\n",
        "# login(\"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\")\n",
        "# Simulated model output\n",
        "# probs = model(X_image, X_query_eval)\n",
        "# top_pred = probs.detach().numpy().squeeze()\n",
        "# For the sake of this example, let's simulate top_pred\n",
        "X_image = torch.tensor(X_image_eval[0]).squeeze().to(device)\n",
        "X_query_eval = torch.tensor(X_text_embed_eval[0]).to(device)\n",
        "probs = model(X_image, X_query_eval).cpu()\n",
        "top_pred = probs.detach().numpy().squeeze()\n",
        "print(top_pred.shape)\n",
        "top_5_indices = np.argsort(top_pred)[-5:][::-1]\n",
        "\n",
        "print(top_5_indices)\n",
        "prompt = ('what is the Alex desk', 1)\n",
        "# Retrieve the image embeddings corresponding to the top predictions\n",
        "retrieved_image_embeddings = [unwrapped_data[prompt][\"image_embeddings_all\"][idx] for idx in top_5_indices]\n",
        "print(([len(x) for x in retrieved_image_embeddings]))\n",
        "print(\"Successfully retrieved image embeddings\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "OCuh-SaN5NEE"
      },
      "outputs": [],
      "source": [
        "def generate_and_tokenize_prompt(prompt, retrieved_image_embeddings):\n",
        "    full_prompt =f\"\"\"Given a target question and a set of image embeddings, representing relevant images related to the question, answer the question in as much detail as possible.\n",
        "### Target question:\n",
        "{prompt[0]+\"?\"}\n",
        "# Image embeddings:\n",
        "{str(retrieved_image_embeddings[:1])}\n",
        "\"\"\"\n",
        "    print(full_prompt)\n",
        "    return full_prompt\n",
        "    # return tokenizer(full_prompt, return_tensors=\"pt\").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4m7zQ5LTVCM",
        "outputId": "4eab1c35-e6fe-4d78-d152-957394abc44c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scale-llm-engine\n",
            "  Downloading scale_llm_engine-0.0.0b33-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: aiohttp<4.0,>=3.8 in /usr/local/lib/python3.10/dist-packages (from scale-llm-engine) (3.9.5)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from scale-llm-engine) (2.7.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from scale-llm-engine) (2.31.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.8->scale-llm-engine) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.8->scale-llm-engine) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.8->scale-llm-engine) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.8->scale-llm-engine) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.8->scale-llm-engine) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.8->scale-llm-engine) (4.0.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->scale-llm-engine) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->scale-llm-engine) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->scale-llm-engine) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->scale-llm-engine) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->scale-llm-engine) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->scale-llm-engine) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->scale-llm-engine) (2024.2.2)\n",
            "Installing collected packages: scale-llm-engine\n",
            "Successfully installed scale-llm-engine-0.0.0b33\n"
          ]
        }
      ],
      "source": [
        "%pip install scale-llm-engine\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "YBGo5aTXVucn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"SCALE_API_KEY\"] = \"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeyTcaAtVJW1",
        "outputId": "0304bc5d-d77b-480a-c82f-0b69d55d3f70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Given a target question and a set of image embeddings, representing relevant images related to the question, answer the question in as much detail as possible.\n",
            "### Target question:\n",
            "what is the Alex desk?\n",
            "# Image embeddings:\n",
            "[[[-0.026401400566101074, -0.005056341644376516, 0.02107362262904644, -0.02604062482714653, 0.022420773282647133, 0.009395401924848557, 0.02781788446009159, 0.03330061584711075, -0.03486843407154083, -0.027320774272084236, 0.0016439397586509585, -0.019156916067004204, 0.08204422891139984, 0.0014538150280714035, 0.029461843892931938, 0.0272693894803524, -0.04049578681588173, 0.03573795408010483, -0.07547422498464584, 0.00340963713824749, -0.0959882140159607, 0.003399668727070093, 0.05353952571749687, 0.01446089893579483, -0.06419672816991806, 0.012848060578107834, 0.006372035481035709, -0.01642022281885147, -0.01827085390686989, 0.04628729447722435, -0.011242721229791641, 0.036169618368148804, 0.02607705071568489, -0.018905164673924446, -0.017777783796191216, -0.01978158950805664, -0.03656540811061859, -0.03366376832127571, 0.00754537945613265, -0.13784347474575043, -0.018873771652579308, 0.026798248291015625, -0.001742577413097024, -0.011118367314338684, -0.010246641002595425, -0.05652491748332977, 0.0008865080308169127, -0.0049352929927408695, -0.03579166531562805, 0.007554586976766586, 0.03350762277841568, 0.017109377309679985, 0.009989316575229168, 0.02808048017323017, -0.0033505228348076344, -0.009482573717832565, -0.009420789778232574, 0.036519985646009445, 0.014796733856201172, 0.04294915869832039, -0.01035341713577509, -0.03360590711236, 0.03847170248627663, 0.04686982184648514, 0.03176134452223778, 0.0005876761279068887, 0.03183043375611305, 0.10405311733484268, -0.057049158960580826, 0.021520955488085747, -0.05007881671190262, 0.01980619691312313, -0.030598409473896027, -0.007245294284075499, 0.018924281001091003, 0.04287711903452873, 0.029768267646431923, -0.02062106691300869, -0.012905252166092396, 0.06250809878110886, 0.018673408776521683, -0.006975468248128891, -0.02941565215587616, 0.07810556143522263, -0.0003387223114259541, -0.002437182702124119, 0.03838106989860535, -0.052447836846113205, -0.036182768642902374, 0.016411742195487022, 0.0089721092954278, -0.04146875813603401, -0.671704888343811, 0.04092579707503319, 0.023060787469148636, 0.0234735868871212, 0.028833122923970222, 0.0037653117906302214, -0.007395723834633827, 0.010500763542950153, 0.010671236552298069, -0.04493972286581993, 0.030165109783411026, -0.004736765753477812, -0.02333097718656063, 0.027109265327453613, -0.10390699654817581, 0.030825892463326454, -0.029728056862950325, -0.0657486841082573, 0.014452914707362652, 0.014846005477011204, 0.034820858389139175, 0.017366092652082443, -0.005129736848175526, -0.05360588803887367, -0.033732105046510696, 0.03298719599843025, -0.016863467171788216, 0.011034796014428139, -0.017437905073165894, 0.037408530712127686, -0.02183457650244236, 0.03423630818724632, 0.017388280481100082, 0.01815817877650261, -0.0018403196008875966, -0.010224652476608753, -0.009137130342423916, 0.047419991344213486, 0.0074367220513522625, 0.05513974651694298, -0.022343577817082405, 0.08791331946849823, -0.011247203685343266, -0.0007304194732569158, -0.010156736709177494, -0.016688179224729538, 0.011955761350691319, 0.029631128534674644, 0.016745690256357193, 0.014939265325665474, -0.042233046144247055, -0.029639096930623055, -0.0036813754122704268, -0.0023484211415052414, 0.021812664344906807, 0.027766084298491478, 0.02926217019557953, -0.05718376487493515, -0.017504844814538956, -0.029063360765576363, 0.10909317433834076, 0.02834847755730152, 0.0014011585153639317, 0.00410029012709856, -0.015654997900128365, 0.040661636739969254, -0.07417622208595276, 0.016422275453805923, -0.020178405568003654, -0.030463170260190964, 0.06323558837175369, -0.004727229475975037, -0.034213483333587646, -0.03303496539592743, 0.0037637678906321526, 0.03407327085733414, 0.016890086233615875, -0.010430249385535717, -0.0172736756503582, -0.010709631256759167, 0.002929146634414792, -0.03633417189121246, -0.01952727697789669, -0.015262698754668236, 0.0566677488386631, -0.008341684937477112, -0.0029450373258441687, 0.034763533622026443, -0.016361553221940994, -0.025363072752952576, 0.007526532746851444, -0.010707824490964413, 0.01464117132127285, 0.03229689598083496, 0.033721406012773514, 0.014228004030883312, 0.008740274235606194, -0.016567591577768326, 0.007275884971022606, 0.010739483870565891, -0.028743932023644447, 0.008546072989702225, -0.014392274431884289, 0.002451542532071471, -0.01442673522979021, -0.006767192855477333, -0.012440239079296589, -0.008022286929190159, 0.03323521837592125, 0.0315035916864872, -0.003113203914836049, -0.013387895189225674, -0.021944671869277954, -0.0114694032818079, -0.01467349287122488, 0.015750039368867874, -0.0025175195187330246, -0.04040892794728279, -0.03968782722949982, 0.028130415827035904, -0.027230041101574898, 0.01222706027328968, -0.06207902356982231, -0.02890794724225998, -0.05459021404385567, 0.004441205877810717, -0.08491650223731995, -0.0046917456202209, 0.011794619262218475, -0.006937942001968622, -0.03155919536948204, -0.005418381653726101, -0.029206708073616028, 0.01641077920794487, -0.016821332275867462, 0.06491804867982864, 0.002067405730485916, -0.012979058548808098, 0.017766902223229408, -0.005123026669025421, -0.03945888206362724, 0.029036035761237144, 0.021277599036693573, -0.03366326540708542, -0.02282564900815487, -0.0057039037346839905, 0.023461434990167618, -0.0036686714738607407, 0.005291198380291462, -0.0030200707260519266, 0.043831389397382736, -0.04365105926990509, -0.011791457422077656, 0.03134676441550255, -0.03101096861064434, 0.05943695828318596, -0.004595398437231779, 0.004125779028981924, 0.018380645662546158, 0.01579980179667473, 0.02123917266726494, -0.011378384195268154, -0.01648719422519207, -0.014178101904690266, 0.002739965682849288, -0.029730895534157753, -0.13350322842597961, 0.033195484429597855, 0.0014988693874329329, 0.020825723186135292, 0.0204914640635252, 0.08524203300476074, 0.0037049727980047464, -0.03884262219071388, 0.013909650966525078, -0.0020729165989905596, -0.018941372632980347, 0.009859473444521427, -0.02907005324959755, 0.0009530459064990282, 0.05658143386244774, 0.04902517795562744, 0.01640026643872261, 0.007873731665313244, -0.024864163249731064, -0.015592167153954506, 0.006183060817420483, 0.0011879096273332834, -0.01177528128027916, 0.012144292704761028, -0.025026483461260796, -0.0024155830033123493, -0.05006744712591171, 0.009377911686897278, 0.007599039934575558, -0.010916737839579582, 0.025920649990439415, 0.024832049384713173, 0.017787465825676918, -0.06797225773334503, 0.04084862396121025, 0.01625228300690651, 0.009770389646291733, 0.03869939222931862, -0.06080438569188118, -0.06268148124217987, 0.0010555022163316607, -0.00507953017950058, 0.011291394010186195, 0.005520554259419441, 0.0028962111100554466, -0.05648591369390488, -0.005096219480037689, 0.010541489347815514, -0.00040183388045988977, 0.0031315560918301344, 0.024355493485927582, -0.010166873224079609, -0.01668701134622097, 0.050010453909635544, 0.08808993548154831, -0.03177132457494736, -0.010587151162326336, 0.011339176446199417, 0.05480168014764786, 0.002417665906250477, 0.02870236337184906, -0.034383583813905716, 0.021159572526812553, 0.12888158857822418, -0.016431689262390137, 0.018376093357801437, 0.02013397216796875, 0.011178706772625446, 0.0017171018989756703, -0.035716984421014786, -0.020097456872463226, 0.007879829034209251, 0.015430714003741741, 0.05125449597835541, 0.028120791539549828, -0.03640687093138695, -0.019220486283302307, 0.02914048172533512, 0.037846557796001434, 0.029438048601150513, -0.019472209736704826, 0.027778534218668938, -0.029261430725455284, 0.029072614386677742, -0.005671006627380848, 0.03627263382077217, 0.025000926107168198, 0.030256707221269608, -0.03847655653953552, -0.022650333121418953, 0.006797361187636852, 0.013490082696080208, 0.07913409173488617, -0.0021438405383378267, -0.037130653858184814, -0.004158946219831705, 0.0024996036663651466, -0.052787791937589645, -0.04955248162150383, 0.048604387789964676, -0.011122728697955608, 0.020982269197702408, 0.00836361013352871, -0.022189443930983543, -0.0068617332726716995, -0.022744914516806602, -0.0016322454903274775, 0.02539726532995701, 0.032885801047086716, 0.02093622274696827, -0.0061738756485283375, -0.006555794272571802, 0.02713766135275364, -0.004184206482023001, 0.011424089781939983, -0.02231123298406601, -0.014798622578382492, -0.03989310935139656, 0.07971476018428802, -0.016909612342715263, -0.050603315234184265, -0.04346318542957306, 0.032284773886203766, -0.01167098619043827, -0.013355609029531479, -0.045828089118003845, 0.0014775461750105023, -0.04622476547956467, 0.013224020600318909, 0.0049151647835969925, -0.0009482179302722216, -0.044155851006507874, -0.011216830462217331, 0.036131300032138824, 0.01830536499619484, -0.0012622689828276634, 0.0017671368550509214, -0.00665010791271925, 0.007241864688694477, -0.015195361338555813, 0.006859363988041878, -0.00185215484816581, 0.00504516763612628, -0.030429372563958168, 0.0633857250213623, -0.02320879139006138, -0.005751500837504864, -0.03156125172972679, 0.00021445189486257732, -0.023750655353069305, -0.03884180635213852, 0.02510666474699974, -0.016179921105504036, 0.03639914467930794, 0.0222102589905262, 0.04065506160259247, 0.052249807864427567, 0.016512807458639145, 0.018534142524003983, 0.019014444202184677, -0.03232068568468094, 0.01028526946902275, -0.04907922446727753, 0.006864506285637617, 0.06078590452671051, 0.06119512766599655, 0.04879644140601158, -0.02864563837647438, -0.03271430358290672, -0.018381787464022636, -0.07609409838914871, 0.004515191074460745, 0.0019385204650461674, 0.06964230537414551, -0.017116740345954895, -0.02631422132253647, -0.04512220621109009, -0.023236406967043877, 0.013850914314389229, -0.015326679684221745, 0.06441841274499893, 0.01675388030707836, 0.01578609272837639, 0.051510877907276154, -0.0020026550628244877, 0.031428854912519455, 0.026938917115330696, -0.010283668525516987, -0.006262864451855421, -0.010142539627850056, 0.02568233758211136, 0.03835044056177139, -0.02998240478336811, -0.007794881239533424, 0.02828056365251541, -0.010623331181704998, 0.018655776977539062, -0.024953151121735573, 0.00423333328217268, -0.0185624398291111, 0.023816457018256187, 0.013447031378746033, -0.017267519608139992, 0.010116588324308395, 0.02453041821718216, -0.004871728830039501, 0.037719693034887314, -0.004513774532824755, 0.0019624517299234867, 0.03690485283732414, 0.01814914494752884, -0.028781820088624954, 0.09909703582525253, 0.038157232105731964, -0.03169531002640724, 0.03547767922282219, -0.02062353491783142, 0.02865120768547058, -0.04578990861773491, 0.031468525528907776, 0.004908619914203882, -0.015753373503684998, -0.03569210693240166, -0.005818396806716919, 0.012409287504851818, -0.03301936760544777, 0.02197028510272503, -0.004289527423679829, 0.004352675285190344, -0.026839176192879677, 0.02915174700319767, -0.05078177899122238, 0.0062200771644711494, 0.0013957088813185692, 0.008700386621057987, -0.03930727392435074, -0.020123545080423355, -0.011919054202735424, 0.050918933004140854, -0.029473476111888885, 0.016586294397711754, 0.02429506555199623, -0.06529207527637482, 0.041016943752765656, 0.03663376718759537, -0.01361391693353653, 0.013246854767203331, 0.005895716603845358, -0.025271600112318993, 0.013403324410319328, -0.0198617372661829, 0.014200975187122822, -0.01809806004166603, -0.050140976905822754]]]\n",
            "\n",
            "---------ANSWER---------\n",
            "# Answer:\n",
            "Alex's desk is a desk that is used by Alex. It is made of wood and has a black finish. The desk has two drawers and a shelf. The desk is located in Alex's bedroom.\n"
          ]
        }
      ],
      "source": [
        "from llmengine import Completion\n",
        "full_prompt = generate_and_tokenize_prompt(prompt, retrieved_image_embeddings)\n",
        "response = Completion.create(\n",
        "    model=\"mixtral-8x7b\",\n",
        "    prompt=full_prompt,\n",
        "    max_new_tokens=1000,\n",
        "    temperature=0.2,\n",
        ")\n",
        "print(\"---------ANSWER---------\")\n",
        "print(response.output.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "H5Ij0pOFVbtg"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "res = response.json()\n",
        "res = json.loads(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xGk_j94HWeFe",
        "outputId": "8618fa80-158a-45b1-b238-ecbb3e91e0d7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res[\"output\"][\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zt_gsZs8WulX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
